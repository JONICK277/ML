{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JONICK277/ML/blob/main/model_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e8aa1d",
      "metadata": {
        "id": "a5e8aa1d"
      },
      "source": [
        "# Model Evaluation with Nested Cross-Validation\n",
        "\n",
        "This notebook performs model evaluation using nested cross-validation for hyperparameter tuning.\n",
        "It then evaluates each model on a held-out validation set and generates predictions on an external test set,\n",
        "saving the results as Excel files for each model."
      ]
    },
    {
      "cell_type": "code",
      "id": "f7f16833",
      "metadata": {
        "id": "f7f16833",
        "ExecuteTime": {
          "end_time": "2025-02-02T12:18:29.899285Z",
          "start_time": "2025-02-02T12:18:29.832719Z"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from math import sqrt\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Data Download ---\n",
        "# Execute this if you are running the notebook in Google Colab\n",
        "!git clone https://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@github.com/JONICK277/ML.git\n",
        "\n",
        "# Load the cleaned data\n",
        "train_cleaned = pd.read_pickle(\"ML/data/cleaned/train/train_cleaned.pkl\")\n",
        "test_cleaned  = pd.read_pickle(\"ML/data/cleaned/test/test_cleaned.pkl\")"
      ],
      "metadata": {
        "id": "r9OVTPBjFd_g"
      },
      "id": "r9OVTPBjFd_g",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Alternatively, if running locally, uncomment the following:\n",
        "train_cleaned = pd.read_pickle(\"./../../data/cleaned/train/train_cleaned.pkl\")\n",
        "test_cleaned  = pd.read_pickle(\"./../../data/cleaned/test/test_cleaned.pkl\")"
      ],
      "metadata": {
        "id": "KcZCSe1hFr-m"
      },
      "id": "KcZCSe1hFr-m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Preparation ---\n",
        "target = \"LAID_UP_TIME\"\n",
        "X = train_cleaned.drop(columns=[target])\n",
        "y = train_cleaned[target]\n",
        "\n",
        "# Split the cleaned training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())\n",
        "    print(\"Standard deviation:\", scores.std())"
      ],
      "metadata": {
        "id": "a8aXKqIsFvSq"
      },
      "id": "a8aXKqIsFvSq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8459aa95",
      "metadata": {
        "id": "8459aa95"
      },
      "source": [
        "## Nested Cross-Validation Function\n",
        "\n",
        "This function performs nested cross-validation: the outer loop estimates the generalization error,\n",
        "and the inner loop tunes hyperparameters using GridSearchCV."
      ]
    },
    {
      "cell_type": "code",
      "id": "b75d6416",
      "metadata": {
        "id": "b75d6416",
        "ExecuteTime": {
          "end_time": "2025-02-02T14:56:00.954684Z",
          "start_time": "2025-02-02T14:56:00.949687Z"
        }
      },
      "source": [
        "def nested_cv(model, param_grid, X, y, model_name, cv_outer=3, cv_inner=2):\n",
        "    outer_cv = KFold(n_splits=cv_outer, shuffle=True, random_state=42)\n",
        "\n",
        "    outer_rmse = []\n",
        "    best_models = []  # Store best model from each fold\n",
        "    best_rmse = float(\"inf\")  # Track the best RMSE\n",
        "    best_model_overall = None  # Store the overall best model\n",
        "\n",
        "    for train_idx, test_idx in outer_cv.split(X):\n",
        "        X_outer_train, X_outer_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_outer_train, y_outer_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Inner CV for hyperparameter tuning\n",
        "        inner_cv = KFold(n_splits=cv_inner, shuffle=True, random_state=42)\n",
        "        gs = GridSearchCV(estimator=model, param_grid=param_grid, cv=inner_cv,\n",
        "                          scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "        gs.fit(X_outer_train, y_outer_train)\n",
        "\n",
        "        # Best model from inner loop\n",
        "        best_model = gs.best_estimator_\n",
        "        best_models.append(best_model)\n",
        "\n",
        "        # Evaluate on the outer test set\n",
        "        y_pred_outer = best_model.predict(X_outer_test)\n",
        "        rmse = sqrt(mean_squared_error(y_outer_test, y_pred_outer))\n",
        "        outer_rmse.append(rmse)\n",
        "\n",
        "        print(f\"{model_name} - Outer fold RMSE: {rmse:.4f}\")\n",
        "\n",
        "        # Keep track of the best model based on RMSE\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_model_overall = best_model\n",
        "\n",
        "    print(f\"\\n--- {model_name} Summary of Nested CV ---\")\n",
        "    print(f\"Mean RMSE: {np.mean(outer_rmse):.4f}\")\n",
        "    print(f\"Best RMSE: {best_rmse:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    model_filename = f\"best_{model_name.lower().replace(' ', '_')}.pkl\"\n",
        "    with open(model_filename, \"wb\") as f:\n",
        "        pickle.dump(best_model_overall, f)\n",
        "\n",
        "    print(f\"Best {model_name} model saved as '{model_filename}'\\n\")\n",
        "\n",
        "    return best_model_overall, outer_rmse"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "dca3d847",
      "metadata": {
        "id": "dca3d847"
      },
      "source": [
        "## Model 1: Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "id": "872e6a45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "872e6a45",
        "outputId": "c8b0f42f-b88e-42a8-9d2c-a6af91404177",
        "ExecuteTime": {
          "end_time": "2025-02-02T16:47:03.167204Z",
          "start_time": "2025-02-02T14:56:31.292031Z"
        },
        "collapsed": true
      },
      "source": [
        "# Define hyperparameter grid for Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [500, 700, 800, 1000],\n",
        "    'max_features': ['sqrt'],\n",
        "    'max_depth': [10, 20, 30],\n",
        "    'min_samples_split': [5, 10, 20],\n",
        "    'min_samples_leaf': [2, 5, 10],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "pprint(param_grid_rf)\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "print(\"\\n--- Random Forest Nested CV ---\")\n",
        "best_rf_model, rf_rmse_scores = nested_cv(rf_model, param_grid_rf, X_train, y_train, \"Random Forest\")\n",
        "print(\"Random Forest Nested CV RMSE scores:\", rf_rmse_scores)\n",
        "print(\"Mean RF Nested RMSE:\", np.mean(rf_rmse_scores))"
      ],
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30],\n",
            " 'max_features': ['sqrt'],\n",
            " 'min_samples_leaf': [2, 5, 10],\n",
            " 'min_samples_split': [5, 10, 20],\n",
            " 'n_estimators': [500, 700, 800, 1000]}\n",
            "\n",
            "--- Random Forest Nested CV ---\n",
            "Random Forest - Outer fold RMSE: 37.3565\n",
            "Random Forest - Outer fold RMSE: 36.5694\n",
            "Random Forest - Outer fold RMSE: 36.6782\n",
            "Random Forest - Outer fold RMSE: 36.9182\n",
            "Random Forest - Outer fold RMSE: 36.8307\n",
            "\n",
            "--- Random Forest Summary of Nested CV ---\n",
            "Mean RMSE: 36.8706\n",
            "Best RMSE: 36.5694\n",
            "Best Random Forest model saved as 'best_random_forest.pkl'\n",
            "\n",
            "Random Forest Nested CV RMSE scores: [37.3564699763197, 36.56940086860443, 36.678233881391684, 36.91815386222192, 36.83070499448742]\n",
            "Mean RF Nested RMSE: 36.87059271660503\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "7ac624c9a775a4fd"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "with open(\"best_random_forest.pkl\", \"rb\") as f:\n",
        "    best_rf_model = pickle.load(f)"
      ],
      "id": "7ac624c9a775a4fd"
    },
    {
      "cell_type": "code",
      "source": [
        "### Random Forest Final Evaluation\n",
        "\n",
        "y_val_pred_rf = best_rf_model.predict(X_val)\n",
        "val_rmse_rf = sqrt(mean_squared_error(y_val, y_val_pred_rf))\n",
        "print(\"\\nFinal Validation RMSE (Random Forest):\", val_rmse_rf)"
      ],
      "metadata": {
        "id": "O5WQO025TEd_",
        "ExecuteTime": {
          "end_time": "2025-02-02T16:47:58.399909Z",
          "start_time": "2025-02-02T16:47:56.423840Z"
        },
        "outputId": "43a4692c-0aad-4642-e4e3-e835a96a3934"
      },
      "id": "O5WQO025TEd_",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Validation RMSE (Random Forest): 36.872580978397785\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tuning on whole dataset for prediction"
      ],
      "metadata": {
        "id": "7AcQs7U0R4No"
      },
      "id": "7AcQs7U0R4No"
    },
    {
      "cell_type": "code",
      "source": [
        "# Final tuning on the entire training set and saving the best model for Random Forest\n",
        "rf_random = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "rf_random.fit(X, y)\n",
        "best_model_rf = rf_random.best_estimator_\n",
        "with open('best_model_forest.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model_rf, f)"
      ],
      "metadata": {
        "id": "O-_T85z0SDkp",
        "ExecuteTime": {
          "end_time": "2025-02-02T17:24:35.257809Z",
          "start_time": "2025-02-02T16:48:47.613186Z"
        }
      },
      "id": "O-_T85z0SDkp",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "c4a754ee",
      "metadata": {
        "id": "c4a754ee"
      },
      "source": [
        "## Model 2: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "id": "3228f46c",
      "metadata": {
        "id": "3228f46c",
        "ExecuteTime": {
          "end_time": "2025-02-02T19:06:28.575149Z",
          "start_time": "2025-02-02T17:30:43.455147Z"
        }
      },
      "source": [
        "# Define hyperparameter grid for XGBoost\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [400, 500, 600, 700, 800, 900, 1000],\n",
        "    'max_depth': [3, 5, 7, 8, 9],\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.4],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "pprint(param_grid_xgb)\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = XGBRegressor(tree_method='hist', device=\"cuda\", random_state=42)\n",
        "print(\"\\n--- XGBoost Nested CV ---\")\n",
        "best_xgb_model, xgb_rmse_scores = nested_cv(xgb_model, param_grid_xgb, X_train, y_train, \"XGBoost\")\n",
        "print(\"XGBoost Nested CV RMSE scores:\", xgb_rmse_scores)\n",
        "print(\"Mean XGBoost Nested RMSE:\", np.mean(xgb_rmse_scores))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "81d3371d652bdeb1"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "with open(\"best_xgboost.pkl\", \"rb\") as f:\n",
        "    best_xgb_model = pickle.load(f)"
      ],
      "id": "81d3371d652bdeb1"
    },
    {
      "cell_type": "code",
      "source": [
        "### XGBoost Final Evaluation\n",
        "y_val_pred_xgb = best_xgb_model.predict(X_val)\n",
        "val_rmse_xgb = sqrt(mean_squared_error(y_val, y_val_pred_xgb))\n",
        "print(\"\\nFinal Validation RMSE (XGBoost):\", val_rmse_xgb)"
      ],
      "metadata": {
        "id": "Nh0S1VzMTHbH"
      },
      "id": "Nh0S1VzMTHbH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tuning on whole dataset for prediction"
      ],
      "metadata": {
        "id": "gOm_ScurSJuI"
      },
      "id": "gOm_ScurSJuI"
    },
    {
      "cell_type": "code",
      "source": [
        "# Final tuning on the entire training set and saving the best model for XGBoost\n",
        "xgb_random = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=3,\n",
        "                          scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "xgb_random.fit(X, y)\n",
        "best_model_xgb = xgb_random.best_estimator_\n",
        "with open('best_model_xgboost.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model_xgb, f)"
      ],
      "metadata": {
        "id": "gEw2Pv7fSMEe"
      },
      "id": "gEw2Pv7fSMEe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f6cfb1e3",
      "metadata": {
        "id": "f6cfb1e3"
      },
      "source": [
        "## Model 3: Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "id": "fcb2aa6b",
      "metadata": {
        "id": "fcb2aa6b",
        "ExecuteTime": {
          "end_time": "2025-02-02T19:08:13.407075Z",
          "start_time": "2025-02-02T19:08:05.467269Z"
        }
      },
      "source": [
        "# Define hyperparameter grid for Gradient Boost\n",
        "param_grid_grad = {\n",
        "    'n_estimators': [ 400, 500, 600, 700],\n",
        "    'max_depth': [3, 5, 7, 8],\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.4],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'min_child_weight': [1, 3, 5, 6, 7]\n",
        "}\n",
        "pprint(param_grid_grad)\n",
        "\n",
        "# Initialize the Gradient Boost model\n",
        "grad_model = XGBRegressor(tree_method='hist', device=\"cpu\", random_state=42)\n",
        "print(\"\\n--- Gradient Boost Nested CV ---\")\n",
        "best_grad_model, grad_rmse_scores = nested_cv(grad_model, param_grid_grad, X_train, y_train, \"Gradient Boosting\")\n",
        "print(\"Gradient Boost Nested CV RMSE scores:\", grad_rmse_scores)\n",
        "print(\"Mean Gradient Boost Nested RMSE:\", np.mean(grad_rmse_scores))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "b079642ac0ca8b5e"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "with open(\"best_gradient_boosting.pkl\", \"rb\") as f:\n",
        "    best_gb_model = pickle.load(f)"
      ],
      "id": "b079642ac0ca8b5e"
    },
    {
      "cell_type": "code",
      "source": [
        "### Gradient Boost Final Evaluation\n",
        "y_val_pred_grad = best_grad_model.predict(X_val)\n",
        "val_rmse_grad = sqrt(mean_squared_error(y_val, y_val_pred_grad))\n",
        "print(\"\\nFinal Validation RMSE (Gradient Boost):\", val_rmse_grad)"
      ],
      "metadata": {
        "id": "fdL--r31TChG"
      },
      "id": "fdL--r31TChG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##tuning on whole dataset for prediction"
      ],
      "metadata": {
        "id": "MDKXvjuQSKWe"
      },
      "id": "MDKXvjuQSKWe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Final tuning on the entire training set and saving the best model for Gradient Boost\n",
        "grad_random = GridSearchCV(estimator=grad_model, param_grid=param_grid_grad, cv=3,\n",
        "                           scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grad_random.fit(X, y)\n",
        "best_model_grad = grad_random.best_estimator_\n",
        "with open('best_model_grad_boost_small_test_set.pkl', 'wb') as f:\n",
        "    pickle.dump(best_model_grad, f)"
      ],
      "metadata": {
        "id": "kgyUsmZkSOKu"
      },
      "id": "kgyUsmZkSOKu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "6f57fa6f",
      "metadata": {
        "id": "6f57fa6f"
      },
      "source": [
        "## Final Evaluation on Validation Set\n",
        "\n",
        "For each model, we load the saved best model, predict on the validation set, compute the RMSE,\n",
        "and then predict on the external test set. The results are saved to Excel files."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on external test set for Random Forest and save results\n",
        "with open('best_model_forest.pkl', 'rb') as f:\n",
        "    best_model_rf = pickle.load(f)\n",
        "\n",
        "test_cleaned_copy = test_cleaned.copy()\n",
        "chassis_number_rf = test_cleaned_copy['CHASSIS_NUMBER']\n",
        "test_cleaned_copy = test_cleaned_copy.drop(columns=['CHASSIS_NUMBER', 'LAID_UP_TIME'])\n",
        "y_test_pred_rf = best_model_rf.predict(test_cleaned_copy)\n",
        "result_rf = pd.DataFrame({\n",
        "    'CHASSIS_NUMBER': chassis_number_rf,\n",
        "    'LAID_UP_TIME': y_test_pred_rf\n",
        "})\n",
        "try:\n",
        "    with open(\"../../results/teamB-model1_RF.xlsx\") as f:\n",
        "        raise FileExistsError\n",
        "except FileNotFoundError:\n",
        "    result_rf.to_excel(\"../../results/teamB-model1_RF.xlsx\", index=False)\n",
        "try:\n",
        "    with open(\"ML/results/teamB-model1_RF.xlsx\") as f:\n",
        "        raise FileExistsError\n",
        "except FileNotFoundError:\n",
        "    result_rf.to_excel(\"ML/results/teamB-model1_RF.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "4VFlgTeOS2Xk",
        "ExecuteTime": {
          "end_time": "2025-02-02T17:28:53.224108Z",
          "start_time": "2025-02-02T17:28:51.663034Z"
        }
      },
      "id": "4VFlgTeOS2Xk",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on external test set for XGBoost and save results\n",
        "with open('best_model_xgboost.pkl', 'rb') as f:\n",
        "    best_model_xgb = pickle.load(f)\n",
        "\n",
        "test_cleaned_copy = test_cleaned.copy()\n",
        "chassis_number_xgb = test_cleaned_copy['CHASSIS_NUMBER']\n",
        "test_cleaned_copy = test_cleaned_copy.drop(columns=['CHASSIS_NUMBER', 'LAID_UP_TIME'])\n",
        "y_test_pred_xgb = best_model_xgb.predict(test_cleaned_copy)\n",
        "result_xgb = pd.DataFrame({\n",
        "    'CHASSIS_NUMBER': chassis_number_xgb,\n",
        "    'LAID_UP_TIME': y_test_pred_xgb\n",
        "})\n",
        "try:\n",
        "    with open(\"../../results/teamB-model2_XGB.xlsx\") as f:\n",
        "        raise FileExistsError\n",
        "except FileNotFoundError:\n",
        "    result_xgb.to_excel(\"../../results/teamB-model2_XGB.xlsx\", index=False)\n",
        "try:\n",
        "    with open(\"ML/results/teamB-model2_XGB.xlsx\") as f:\n",
        "        raise FileExistsError\n",
        "except FileNotFoundError:\n",
        "    result_xgb.to_excel(\"ML/results/teamB-model2_XGB.xlsx\", index=False)\n"
      ],
      "metadata": {
        "id": "i7cUadeOTW6n"
      },
      "id": "i7cUadeOTW6n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e25e8f7",
      "metadata": {
        "id": "3e25e8f7"
      },
      "outputs": [],
      "source": [
        "# Predict on external test set for Gradient Boost and save results\n",
        "with open('best_model_grad_boost_small_test_set.pkl', 'rb') as f:\n",
        "    best_model_grad = pickle.load(f)\n",
        "\n",
        "test_cleaned_copy = test_cleaned.copy()\n",
        "chassis_number_grad = test_cleaned_copy['CHASSIS_NUMBER']\n",
        "test_cleaned_copy = test_cleaned_copy.drop(columns=['CHASSIS_NUMBER', 'LAID_UP_TIME'])\n",
        "y_test_pred_grad = best_model_grad.predict(test_cleaned_copy)\n",
        "result_grad = pd.DataFrame({\n",
        "    'CHASSIS_NUMBER': chassis_number_grad,\n",
        "    'LAID_UP_TIME': y_test_pred_grad\n",
        "})\n",
        "try:\n",
        "    with open(\"../../results/teamB-model3_Grad.xlsx\") as f:\n",
        "        raise FileExistsError\n",
        "except FileNotFoundError:\n",
        "    result_grad.to_excel(\"../../results/teamB-model3_Grad.xlsx\", index=False)\n",
        "try:\n",
        "    with open(\"ML/results/teamB-model3_Grad.xlsx\") as f:\n",
        "        raise FileExistsError\n",
        "except FileNotFoundError:\n",
        "    result_grad.to_excel(\"ML/results/teamB-model3_Grad.xlsx\", index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}